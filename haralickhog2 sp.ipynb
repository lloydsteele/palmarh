{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "\n",
    "from skimage.filters import roberts, scharr, prewitt, sobel, hessian, frangi, sato, threshold_yen\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from skimage.exposure import equalize_hist\n",
    "from skimage.measure import label, regionprops, regionprops_table\n",
    "from skimage.morphology import erosion, dilation\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.filters import gaussian\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "import numpy as np\n",
    "from skimage import io, color, img_as_ubyte\n",
    "from skimage.measure import label, regionprops, regionprops_table\n",
    "from skimage.feature import hog, corner_moravec, greycomatrix, greycoprops, canny\n",
    "from skimage.exposure import equalize_hist\n",
    "from skimage.filters import sato\n",
    "from skimage import data, exposure, feature\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report,accuracy_score, confusion_matrix \n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "from scipy.stats import mannwhitneyu, f_oneway\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "HOG + HARALICK\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def HOGex(img, path):\n",
    "    H = feature.hog(img, orientations=orientation, pixels_per_cell=pixelspercell, cells_per_block=cellsperblock,\n",
    "            transform_sqrt=True, block_norm=\"L1\")\n",
    "    return H\n",
    "def GLCMex(img, path):\n",
    "    glcm = greycomatrix(img, \n",
    "            distances=distances, \n",
    "            angles=angles,\n",
    "            symmetric=symmetric,\n",
    "            normed=normed)\n",
    "    properties=['contrast', 'dissimilarity', 'homogeneity', 'energy',\n",
    "                        'correlation', 'ASM']\n",
    "    feats = np.hstack([greycoprops(glcm, prop).ravel() for prop in properties])\n",
    "    return feats\n",
    "\n",
    "\n",
    "\n",
    "def imageloader(paths, filter_on=False, norm=False, test=False, properties=['contrast', 'dissimilarity', 'homogeneity', 'energy',\n",
    "                          'correlation', 'ASM']):\n",
    "    for path in paths:\n",
    "        print(path)\n",
    "        for i, image_path in enumerate(os.listdir(path)):\n",
    "            if not image_path.startswith('.'):\n",
    "                if test == True:\n",
    "                    if i > 5:\n",
    "                        break\n",
    "                print(f\"{i+1} of {len(os.listdir(path))}\")  \n",
    "                input_path = os.path.join(path, image_path)\n",
    "                img = io.imread(input_path, as_gray=True)\n",
    "                img = resize(img, (yy, xx))\n",
    "                if norm == True:\n",
    "                    img= equalize_hist(img)\n",
    "                if filter_on == True:\n",
    "                    img= sato(img)\n",
    "                img = img_as_ubyte(img)\n",
    "                \"\"\"\n",
    "                featureextraction\n",
    "                \"\"\"\n",
    "                H = HOGex(img, path)\n",
    "                feats = GLCMex(img, path)\n",
    "                \"\"\"\n",
    "                store\n",
    "                \"\"\"\n",
    "                datahog.append(H)\n",
    "                dataglcm.append(feats)\n",
    "                globalfeat = np.hstack([H, feats])\n",
    "                globalfeats.append(globalfeat)\n",
    "                if path == paths[0]:\n",
    "                    flg=1\n",
    "                    globallabels.append(flg)\n",
    "                    labelsglcm.append(flg)\n",
    "                    labelshog.append(flg)\n",
    "                if path == paths[1]:\n",
    "                    flg=0\n",
    "                    globallabels.append(flg)\n",
    "                    labelsglcm.append(flg)\n",
    "                    labelshog.append(flg)\n",
    "\n",
    "def GLCMHOGtest():\n",
    "    for name, model in models:\n",
    "        kfold = KFold(n_splits=kfoldsplits) #random_state=seed)\n",
    "        cv_results = cross_val_score(model, trainDataGlobal, trainLabelsGlobal, cv=kfold, scoring=scoring)\n",
    "        results.append(cv_results)\n",
    "        print(f\"results: {cv_results}\")\n",
    "        names.append(name)\n",
    "        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "        print(msg)\n",
    "        \n",
    "    # boxplot algorithm comparison\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.boxplot(results)\n",
    "#    showmeans=True\n",
    "    ax.set_xticklabels(names)\n",
    "    plt.show()\n",
    "    \n",
    "def GLCMHOGtest2():\n",
    "    for name, model in models:\n",
    "        kfold = KFold(n_splits=kfoldsplits) #random_state=seed)\n",
    "        cv_results = cross_val_score(model, trainDataGlobal, trainLabelsGlobal, cv=kfold, scoring=scoring)\n",
    "        results.append(cv_results)\n",
    "        #print(f\"results: {cv_results}\")\n",
    "        names.append(name)\n",
    "        print(f\"{name}: mean is {cv_results.mean()*100:.1f}% with SD {cv_results.std()*100.0:.1f}\")\n",
    "    # boxplot algorithm comparison\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.boxplot(results)\n",
    "#    showmeans=True\n",
    "    ax.set_xticklabels(names)\n",
    "    plt.show()\n",
    "            #msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    \n",
    "    \n",
    "print(\"done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thenar WT photo count: 325\n",
      "Palmar WT photo count: 325\n",
      "Thenar FLG photo count: 208\n",
      "Palmar FLG photo count: 208\n",
      "TOTAL photo count: 533\n",
      "hrtro photo count: 180\n",
      "homor photo count: 29\n",
      "joint photo count: 208\n"
     ]
    }
   ],
   "source": [
    "base_dir = '/Users/L/Downloads/palmarhyperlinearity/'\n",
    "base_dir_thenar = '/Users/L/Downloads/palmarhyperlinearity/thenarversionall2/'\n",
    "base_dir_p = '/Users/L/Downloads/palmarhyperlinearity/palmarversionall2/'\n",
    "\n",
    "train_dir_flg_thenar = os.path.join(base_dir_thenar, 'flg')\n",
    "train_dir_wt_thenar = os.path.join(base_dir_thenar, 'wtupdated')\n",
    "\n",
    "train_dir_flg_palm = os.path.join(base_dir_p, 'flg')\n",
    "train_dir_wt_palm = os.path.join(base_dir_p, 'wt')\n",
    "\n",
    "\n",
    "print(f\"Thenar WT photo count: {len(os.listdir(train_dir_wt_thenar))}\")\n",
    "print(f\"Palmar WT photo count: {len(os.listdir(train_dir_wt_palm))}\")\n",
    "\n",
    "print(f\"Thenar FLG photo count: {len(os.listdir(train_dir_flg_thenar))}\")\n",
    "print(f\"Palmar FLG photo count: {len(os.listdir(train_dir_flg_palm ))}\")\n",
    "\n",
    "print(f\"TOTAL photo count: {(len(os.listdir(train_dir_flg_palm))+len(os.listdir(train_dir_wt_palm)))}\")\n",
    "\n",
    "hetero = os.path.join(base_dir_p, 'het')\n",
    "homo = os.path.join(base_dir_p, 'homo')\n",
    "print(f\"hrtro photo count: {len(os.listdir(hetero))}\") ##I THINK THIS INCLUDES .FILE\n",
    "print(f\"homor photo count: {len(os.listdir(homo))}\")\n",
    "flg2 = os.path.join(base_dir_p, 'flg2')\n",
    "print(f\"joint photo count: {len(os.listdir(flg2))}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor fname in os.listdir(homo):\\n    if not fname.startswith(\\'.\\'):\\n        if fname in os.listdir(flg2):\\n            thisisfantastic = \\'achieved\\'\\n        else:\\n            print(f\"this wasn\\'t copied: {fname}\")\\n            \\n            \\nfor fname in os.listdir(hetero):\\n    #if not fname.startswith(\\'.\\'):\\n    if fname in os.listdir(homo):\\n        print(f\"this duplocaye\\'t copied: {fname}\")\\n    else:\\n        expected=\\'yes\\'\\n'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/L/Downloads/palmarhyperlinearity/thenarversionall2/flg\n",
      "1 of 209\n",
      "2 of 209\n",
      "3 of 209\n",
      "4 of 209\n",
      "5 of 209\n",
      "6 of 209\n",
      "7 of 209\n",
      "8 of 209\n",
      "9 of 209\n",
      "10 of 209\n",
      "11 of 209\n",
      "12 of 209\n",
      "13 of 209\n",
      "14 of 209\n",
      "15 of 209\n",
      "16 of 209\n",
      "17 of 209\n",
      "18 of 209\n",
      "19 of 209\n",
      "20 of 209\n",
      "21 of 209\n",
      "22 of 209\n",
      "23 of 209\n",
      "24 of 209\n",
      "25 of 209\n",
      "26 of 209\n",
      "27 of 209\n",
      "28 of 209\n",
      "29 of 209\n",
      "30 of 209\n",
      "31 of 209\n",
      "32 of 209\n",
      "33 of 209\n",
      "34 of 209\n",
      "35 of 209\n",
      "37 of 209\n",
      "38 of 209\n",
      "39 of 209\n",
      "40 of 209\n",
      "41 of 209\n",
      "42 of 209\n",
      "43 of 209\n",
      "44 of 209\n",
      "45 of 209\n",
      "46 of 209\n",
      "47 of 209\n",
      "48 of 209\n",
      "49 of 209\n",
      "50 of 209\n",
      "51 of 209\n",
      "52 of 209\n",
      "53 of 209\n",
      "54 of 209\n",
      "55 of 209\n",
      "56 of 209\n",
      "57 of 209\n",
      "58 of 209\n",
      "59 of 209\n",
      "60 of 209\n",
      "61 of 209\n",
      "62 of 209\n",
      "63 of 209\n",
      "64 of 209\n",
      "65 of 209\n",
      "66 of 209\n",
      "67 of 209\n",
      "68 of 209\n",
      "69 of 209\n",
      "70 of 209\n",
      "71 of 209\n",
      "72 of 209\n",
      "73 of 209\n",
      "74 of 209\n",
      "75 of 209\n",
      "76 of 209\n",
      "77 of 209\n",
      "78 of 209\n",
      "79 of 209\n",
      "80 of 209\n",
      "81 of 209\n",
      "82 of 209\n",
      "83 of 209\n",
      "84 of 209\n",
      "85 of 209\n",
      "86 of 209\n",
      "87 of 209\n",
      "88 of 209\n",
      "89 of 209\n",
      "90 of 209\n",
      "91 of 209\n",
      "92 of 209\n",
      "93 of 209\n",
      "94 of 209\n",
      "95 of 209\n",
      "96 of 209\n",
      "97 of 209\n",
      "98 of 209\n",
      "99 of 209\n",
      "100 of 209\n",
      "101 of 209\n",
      "102 of 209\n",
      "103 of 209\n",
      "104 of 209\n",
      "105 of 209\n",
      "106 of 209\n",
      "107 of 209\n",
      "108 of 209\n",
      "109 of 209\n",
      "110 of 209\n",
      "111 of 209\n",
      "112 of 209\n",
      "113 of 209\n",
      "114 of 209\n",
      "115 of 209\n",
      "116 of 209\n",
      "117 of 209\n",
      "118 of 209\n",
      "119 of 209\n",
      "120 of 209\n",
      "121 of 209\n",
      "122 of 209\n",
      "123 of 209\n",
      "124 of 209\n",
      "125 of 209\n",
      "126 of 209\n",
      "127 of 209\n",
      "128 of 209\n",
      "129 of 209\n",
      "130 of 209\n",
      "131 of 209\n",
      "132 of 209\n",
      "133 of 209\n",
      "134 of 209\n",
      "135 of 209\n",
      "136 of 209\n",
      "137 of 209\n",
      "138 of 209\n",
      "139 of 209\n",
      "140 of 209\n",
      "141 of 209\n",
      "142 of 209\n",
      "143 of 209\n",
      "144 of 209\n",
      "145 of 209\n",
      "146 of 209\n",
      "147 of 209\n",
      "148 of 209\n",
      "149 of 209\n",
      "150 of 209\n",
      "151 of 209\n",
      "152 of 209\n",
      "153 of 209\n",
      "154 of 209\n",
      "155 of 209\n",
      "156 of 209\n",
      "157 of 209\n",
      "158 of 209\n",
      "159 of 209\n",
      "160 of 209\n",
      "161 of 209\n",
      "162 of 209\n",
      "163 of 209\n",
      "164 of 209\n",
      "165 of 209\n",
      "166 of 209\n",
      "167 of 209\n",
      "168 of 209\n",
      "169 of 209\n",
      "170 of 209\n",
      "171 of 209\n",
      "172 of 209\n",
      "173 of 209\n",
      "174 of 209\n",
      "175 of 209\n",
      "176 of 209\n",
      "177 of 209\n",
      "178 of 209\n",
      "179 of 209\n",
      "180 of 209\n",
      "181 of 209\n",
      "182 of 209\n",
      "183 of 209\n",
      "184 of 209\n",
      "185 of 209\n",
      "186 of 209\n",
      "187 of 209\n",
      "188 of 209\n",
      "189 of 209\n",
      "190 of 209\n",
      "191 of 209\n",
      "192 of 209\n",
      "193 of 209\n",
      "194 of 209\n",
      "195 of 209\n",
      "196 of 209\n",
      "197 of 209\n",
      "198 of 209\n",
      "199 of 209\n",
      "200 of 209\n",
      "201 of 209\n",
      "202 of 209\n",
      "203 of 209\n",
      "204 of 209\n",
      "205 of 209\n",
      "206 of 209\n",
      "207 of 209\n",
      "208 of 209\n",
      "209 of 209\n",
      "/Users/L/Downloads/palmarhyperlinearity/thenarversionall2/wtupdated\n",
      "1 of 325\n",
      "2 of 325\n",
      "3 of 325\n",
      "4 of 325\n",
      "5 of 325\n",
      "6 of 325\n",
      "7 of 325\n",
      "8 of 325\n",
      "9 of 325\n",
      "10 of 325\n",
      "11 of 325\n",
      "12 of 325\n",
      "13 of 325\n",
      "14 of 325\n",
      "15 of 325\n",
      "16 of 325\n",
      "17 of 325\n",
      "18 of 325\n",
      "19 of 325\n",
      "20 of 325\n",
      "21 of 325\n",
      "22 of 325\n",
      "23 of 325\n",
      "24 of 325\n",
      "25 of 325\n",
      "26 of 325\n",
      "27 of 325\n",
      "28 of 325\n",
      "29 of 325\n",
      "30 of 325\n",
      "31 of 325\n",
      "32 of 325\n",
      "33 of 325\n",
      "34 of 325\n",
      "35 of 325\n",
      "36 of 325\n",
      "37 of 325\n",
      "38 of 325\n",
      "39 of 325\n",
      "40 of 325\n",
      "41 of 325\n",
      "42 of 325\n",
      "43 of 325\n",
      "44 of 325\n",
      "45 of 325\n",
      "46 of 325\n",
      "47 of 325\n",
      "48 of 325\n",
      "49 of 325\n",
      "51 of 325\n",
      "52 of 325\n",
      "53 of 325\n",
      "54 of 325\n",
      "55 of 325\n",
      "56 of 325\n",
      "57 of 325\n",
      "58 of 325\n",
      "59 of 325\n",
      "60 of 325\n",
      "61 of 325\n",
      "62 of 325\n",
      "63 of 325\n",
      "64 of 325\n",
      "65 of 325\n",
      "66 of 325\n",
      "67 of 325\n",
      "68 of 325\n",
      "69 of 325\n",
      "70 of 325\n",
      "71 of 325\n",
      "72 of 325\n",
      "73 of 325\n",
      "74 of 325\n",
      "75 of 325\n",
      "76 of 325\n",
      "77 of 325\n",
      "78 of 325\n",
      "79 of 325\n",
      "80 of 325\n",
      "81 of 325\n",
      "82 of 325\n",
      "83 of 325\n",
      "84 of 325\n",
      "85 of 325\n",
      "86 of 325\n",
      "87 of 325\n",
      "88 of 325\n",
      "89 of 325\n",
      "90 of 325\n",
      "91 of 325\n",
      "92 of 325\n",
      "93 of 325\n",
      "94 of 325\n",
      "95 of 325\n",
      "96 of 325\n",
      "97 of 325\n",
      "98 of 325\n",
      "99 of 325\n",
      "100 of 325\n",
      "101 of 325\n",
      "102 of 325\n",
      "103 of 325\n",
      "104 of 325\n",
      "105 of 325\n",
      "106 of 325\n",
      "107 of 325\n",
      "108 of 325\n",
      "109 of 325\n",
      "110 of 325\n",
      "111 of 325\n",
      "112 of 325\n",
      "113 of 325\n",
      "114 of 325\n",
      "115 of 325\n",
      "116 of 325\n",
      "117 of 325\n",
      "118 of 325\n",
      "119 of 325\n",
      "120 of 325\n",
      "121 of 325\n",
      "122 of 325\n",
      "123 of 325\n",
      "124 of 325\n",
      "125 of 325\n",
      "126 of 325\n",
      "127 of 325\n",
      "128 of 325\n",
      "129 of 325\n",
      "130 of 325\n",
      "131 of 325\n",
      "132 of 325\n",
      "133 of 325\n",
      "134 of 325\n",
      "135 of 325\n",
      "136 of 325\n",
      "137 of 325\n",
      "138 of 325\n",
      "139 of 325\n",
      "140 of 325\n",
      "141 of 325\n",
      "142 of 325\n",
      "143 of 325\n",
      "144 of 325\n",
      "145 of 325\n",
      "146 of 325\n",
      "147 of 325\n",
      "148 of 325\n",
      "149 of 325\n",
      "150 of 325\n",
      "151 of 325\n",
      "152 of 325\n",
      "153 of 325\n",
      "154 of 325\n",
      "155 of 325\n",
      "156 of 325\n",
      "157 of 325\n",
      "158 of 325\n",
      "159 of 325\n",
      "160 of 325\n",
      "161 of 325\n",
      "162 of 325\n",
      "163 of 325\n",
      "164 of 325\n",
      "165 of 325\n",
      "166 of 325\n",
      "167 of 325\n",
      "168 of 325\n",
      "169 of 325\n",
      "170 of 325\n",
      "171 of 325\n",
      "172 of 325\n",
      "173 of 325\n",
      "174 of 325\n",
      "175 of 325\n",
      "176 of 325\n",
      "177 of 325\n",
      "178 of 325\n",
      "179 of 325\n",
      "180 of 325\n",
      "181 of 325\n",
      "182 of 325\n",
      "183 of 325\n",
      "184 of 325\n",
      "185 of 325\n",
      "186 of 325\n",
      "187 of 325\n",
      "188 of 325\n",
      "189 of 325\n",
      "190 of 325\n",
      "191 of 325\n",
      "192 of 325\n",
      "193 of 325\n",
      "194 of 325\n",
      "195 of 325\n",
      "196 of 325\n",
      "197 of 325\n",
      "198 of 325\n",
      "199 of 325\n",
      "200 of 325\n",
      "201 of 325\n",
      "202 of 325\n",
      "203 of 325\n",
      "204 of 325\n",
      "205 of 325\n",
      "206 of 325\n",
      "207 of 325\n",
      "208 of 325\n",
      "209 of 325\n",
      "210 of 325\n",
      "211 of 325\n",
      "212 of 325\n",
      "213 of 325\n",
      "214 of 325\n",
      "215 of 325\n",
      "216 of 325\n",
      "217 of 325\n",
      "218 of 325\n",
      "219 of 325\n",
      "220 of 325\n",
      "221 of 325\n",
      "222 of 325\n",
      "223 of 325\n",
      "224 of 325\n",
      "225 of 325\n",
      "226 of 325\n",
      "227 of 325\n",
      "228 of 325\n",
      "229 of 325\n",
      "230 of 325\n",
      "231 of 325\n",
      "232 of 325\n",
      "233 of 325\n",
      "234 of 325\n",
      "235 of 325\n",
      "236 of 325\n",
      "237 of 325\n",
      "238 of 325\n",
      "239 of 325\n",
      "240 of 325\n",
      "241 of 325\n",
      "242 of 325\n",
      "243 of 325\n",
      "244 of 325\n",
      "245 of 325\n",
      "246 of 325\n",
      "247 of 325\n",
      "248 of 325\n",
      "249 of 325\n",
      "250 of 325\n",
      "251 of 325\n",
      "252 of 325\n",
      "253 of 325\n",
      "254 of 325\n",
      "255 of 325\n",
      "256 of 325\n",
      "257 of 325\n",
      "258 of 325\n",
      "259 of 325\n",
      "260 of 325\n",
      "261 of 325\n",
      "262 of 325\n",
      "263 of 325\n",
      "264 of 325\n",
      "265 of 325\n",
      "266 of 325\n",
      "267 of 325\n",
      "268 of 325\n",
      "269 of 325\n",
      "270 of 325\n",
      "271 of 325\n",
      "272 of 325\n",
      "273 of 325\n",
      "274 of 325\n",
      "275 of 325\n",
      "276 of 325\n",
      "277 of 325\n",
      "278 of 325\n",
      "279 of 325\n",
      "280 of 325\n",
      "281 of 325\n",
      "282 of 325\n",
      "283 of 325\n",
      "284 of 325\n",
      "285 of 325\n",
      "286 of 325\n",
      "287 of 325\n",
      "288 of 325\n",
      "289 of 325\n",
      "290 of 325\n",
      "291 of 325\n",
      "292 of 325\n",
      "293 of 325\n",
      "294 of 325\n",
      "295 of 325\n",
      "296 of 325\n",
      "297 of 325\n",
      "298 of 325\n",
      "299 of 325\n",
      "300 of 325\n",
      "301 of 325\n",
      "302 of 325\n",
      "303 of 325\n",
      "304 of 325\n",
      "305 of 325\n",
      "306 of 325\n",
      "307 of 325\n",
      "308 of 325\n",
      "309 of 325\n",
      "310 of 325\n",
      "311 of 325\n",
      "312 of 325\n",
      "313 of 325\n",
      "314 of 325\n",
      "315 of 325\n",
      "316 of 325\n",
      "317 of 325\n",
      "318 of 325\n",
      "319 of 325\n",
      "320 of 325\n",
      "321 of 325\n",
      "322 of 325\n",
      "323 of 325\n",
      "324 of 325\n",
      "325 of 325\n"
     ]
    }
   ],
   "source": [
    "##Joint settings\n",
    "yy = 128  *4\n",
    "xx = 64 * 4\n",
    "\n",
    "###GLCM settings\n",
    "distances = [1, 2, 4] \n",
    "angles = [0, np.pi/4, np.pi/2]\n",
    "    #angles = [0, np.pi/4, np.pi/3]\n",
    "symmetric=False\n",
    "normed=True\n",
    "properties = ['contrast', 'dissimilarity', 'homogeneity', 'energy',\n",
    "                          'correlation', 'ASM']\n",
    "###HOG settings\n",
    "orientation=9\n",
    "cellsperblock = (2, 2)\n",
    "pixelspercell = (16, 16)\n",
    "\n",
    "\n",
    "\n",
    "###lists\n",
    "datahog = []\n",
    "labelshog = []\n",
    "dataglcm = []\n",
    "labelsglcm = []\n",
    "globalfeats = []\n",
    "globallabels = []\n",
    "\n",
    "\n",
    "###LISTS\n",
    "datahog = []\n",
    "labelshog = []\n",
    "dataglcm = []\n",
    "labelsglcm = []\n",
    "globalfeats = []\n",
    "globallabels = []\n",
    "\n",
    "###FLG MUST BE PATH[0]\n",
    "paths = [train_dir_flg_thenar, train_dir_wt_thenar]\n",
    "imageloader(paths, filter_on=False, norm=False)\n",
    "\n",
    "seed      = 9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training classifier...\n",
      "done\n",
      "[STATUS] splitted train and test data...\n",
      "Train data  : (478, 54)\n",
      "Test data   : (54, 54)\n",
      "Train labels: (478,)\n",
      "Test labels : (54,)\n"
     ]
    }
   ],
   "source": [
    "###GLCM TESTING 1 OF 2\n",
    "print(\"[INFO] training classifier...\")\n",
    "models = []\n",
    "models.append(('3NN', KNeighborsClassifier(n_neighbors=3)))\n",
    "models.append(('5NN', KNeighborsClassifier(n_neighbors=5)))\n",
    "models.append(('SVM-L', LinearSVC(random_state=seed, dual=False)))\n",
    "models.append(('SVM-rbf', svm.SVC(kernel='rbf')))\n",
    "print(\"done\")\n",
    "\n",
    "test_size=0.10\n",
    "seed=9\n",
    "kfoldsplits=10\n",
    "datasetx = dataglcm\n",
    "labelsx = labelsglcm\n",
    "trainDataGlobal, testDataGlobal, trainLabelsGlobal, testLabelsGlobal = train_test_split(np.array(datasetx),\n",
    "                                                                                          np.array(labelsx),\n",
    "                                                                                          test_size=test_size,\n",
    "                                                                                          random_state=seed                                                                           #shuffle=True) \n",
    "                                                                                                    \n",
    "print(\"[STATUS] splitted train and test data...\")\n",
    "print(\"Train data  : {}\".format(trainDataGlobal.shape))\n",
    "print(\"Test data   : {}\".format(testDataGlobal.shape))\n",
    "print(\"Train labels: {}\".format(trainLabelsGlobal.shape))\n",
    "print(\"Test labels : {}\".format(testLabelsGlobal.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "####GLCM 2 V2 tehnar\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import make_scorer\n",
    "specificity = make_scorer(recall_score, pos_label=0) #The label 0 is usually the negative class in a binary problem.\n",
    "sensitivity = make_scorer(recall_score, pos_label=1)\n",
    "\n",
    "\n",
    "results = []\n",
    "names   = []\n",
    "\n",
    "#scoring = 'accuracy'\n",
    "#scoring = sensitivity\n",
    "scoring = specificity\n",
    "\n",
    "\n",
    "GLCMHOGtest2()                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] feature vector size (502, 16794)\n",
      "[STATUS] training Labels (502,)\n"
     ]
    }
   ],
   "source": [
    "# get the overall feature vector size\n",
    "print(\"[STATUS] feature vector size {}\".format(np.array(globalfeats).shape))\n",
    "\n",
    "# get the overall training label size\n",
    "print(\"[STATUS] training Labels {}\".format(np.array(globallabels).shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/L/Downloads/palmarhyperlinearity/palmarversionall2/flg\n",
      "1 of 209\n",
      "2 of 209\n",
      "3 of 209\n",
      "4 of 209\n",
      "5 of 209\n",
      "6 of 209\n",
      "7 of 209\n",
      "8 of 209\n",
      "9 of 209\n",
      "10 of 209\n",
      "11 of 209\n",
      "12 of 209\n",
      "13 of 209\n",
      "14 of 209\n",
      "15 of 209\n",
      "16 of 209\n",
      "17 of 209\n",
      "18 of 209\n",
      "19 of 209\n",
      "20 of 209\n",
      "21 of 209\n",
      "22 of 209\n",
      "23 of 209\n",
      "24 of 209\n",
      "25 of 209\n",
      "26 of 209\n",
      "27 of 209\n",
      "28 of 209\n",
      "29 of 209\n",
      "30 of 209\n",
      "31 of 209\n",
      "32 of 209\n",
      "33 of 209\n",
      "35 of 209\n",
      "36 of 209\n",
      "37 of 209\n",
      "38 of 209\n",
      "39 of 209\n",
      "40 of 209\n",
      "41 of 209\n",
      "42 of 209\n",
      "43 of 209\n",
      "44 of 209\n",
      "45 of 209\n",
      "46 of 209\n",
      "47 of 209\n",
      "48 of 209\n",
      "49 of 209\n",
      "50 of 209\n",
      "51 of 209\n",
      "52 of 209\n",
      "53 of 209\n",
      "54 of 209\n",
      "55 of 209\n",
      "56 of 209\n",
      "57 of 209\n",
      "58 of 209\n",
      "59 of 209\n",
      "60 of 209\n",
      "61 of 209\n",
      "62 of 209\n",
      "63 of 209\n",
      "64 of 209\n",
      "65 of 209\n",
      "66 of 209\n",
      "67 of 209\n",
      "68 of 209\n",
      "69 of 209\n",
      "70 of 209\n",
      "71 of 209\n",
      "72 of 209\n",
      "73 of 209\n",
      "74 of 209\n",
      "75 of 209\n",
      "76 of 209\n",
      "77 of 209\n",
      "78 of 209\n",
      "79 of 209\n",
      "80 of 209\n",
      "81 of 209\n",
      "82 of 209\n",
      "83 of 209\n",
      "84 of 209\n",
      "85 of 209\n",
      "86 of 209\n",
      "87 of 209\n",
      "88 of 209\n",
      "89 of 209\n",
      "90 of 209\n",
      "91 of 209\n",
      "92 of 209\n",
      "93 of 209\n",
      "94 of 209\n",
      "95 of 209\n",
      "96 of 209\n",
      "97 of 209\n",
      "98 of 209\n",
      "99 of 209\n",
      "100 of 209\n",
      "101 of 209\n",
      "102 of 209\n",
      "103 of 209\n",
      "104 of 209\n",
      "105 of 209\n",
      "106 of 209\n",
      "107 of 209\n",
      "108 of 209\n",
      "109 of 209\n",
      "110 of 209\n",
      "111 of 209\n",
      "112 of 209\n",
      "113 of 209\n",
      "114 of 209\n",
      "115 of 209\n",
      "116 of 209\n",
      "117 of 209\n",
      "118 of 209\n",
      "119 of 209\n",
      "120 of 209\n",
      "121 of 209\n",
      "122 of 209\n",
      "123 of 209\n",
      "124 of 209\n",
      "125 of 209\n",
      "126 of 209\n",
      "127 of 209\n",
      "128 of 209\n",
      "129 of 209\n",
      "130 of 209\n",
      "131 of 209\n",
      "132 of 209\n",
      "133 of 209\n",
      "134 of 209\n",
      "135 of 209\n",
      "136 of 209\n",
      "137 of 209\n",
      "138 of 209\n",
      "139 of 209\n",
      "140 of 209\n",
      "141 of 209\n",
      "142 of 209\n",
      "143 of 209\n",
      "144 of 209\n",
      "145 of 209\n",
      "146 of 209\n",
      "147 of 209\n",
      "148 of 209\n",
      "149 of 209\n",
      "150 of 209\n",
      "151 of 209\n",
      "152 of 209\n",
      "153 of 209\n",
      "154 of 209\n",
      "155 of 209\n",
      "156 of 209\n",
      "157 of 209\n",
      "158 of 209\n",
      "159 of 209\n",
      "160 of 209\n",
      "161 of 209\n",
      "162 of 209\n",
      "163 of 209\n",
      "164 of 209\n",
      "165 of 209\n",
      "166 of 209\n",
      "167 of 209\n",
      "168 of 209\n",
      "169 of 209\n",
      "170 of 209\n",
      "171 of 209\n",
      "172 of 209\n",
      "173 of 209\n",
      "174 of 209\n",
      "175 of 209\n",
      "176 of 209\n",
      "177 of 209\n",
      "178 of 209\n",
      "179 of 209\n",
      "180 of 209\n",
      "181 of 209\n",
      "182 of 209\n",
      "183 of 209\n",
      "184 of 209\n",
      "185 of 209\n",
      "186 of 209\n",
      "187 of 209\n",
      "188 of 209\n",
      "189 of 209\n",
      "190 of 209\n",
      "191 of 209\n",
      "192 of 209\n",
      "193 of 209\n",
      "194 of 209\n",
      "195 of 209\n",
      "196 of 209\n",
      "197 of 209\n",
      "198 of 209\n",
      "199 of 209\n",
      "200 of 209\n",
      "201 of 209\n",
      "202 of 209\n",
      "203 of 209\n",
      "204 of 209\n",
      "205 of 209\n",
      "206 of 209\n",
      "207 of 209\n",
      "208 of 209\n",
      "209 of 209\n",
      "/Users/L/Downloads/palmarhyperlinearity/palmarversionall2/wt\n",
      "1 of 325\n",
      "2 of 325\n",
      "3 of 325\n",
      "4 of 325\n",
      "5 of 325\n",
      "6 of 325\n",
      "7 of 325\n",
      "8 of 325\n",
      "9 of 325\n",
      "10 of 325\n",
      "11 of 325\n",
      "12 of 325\n",
      "13 of 325\n",
      "14 of 325\n",
      "15 of 325\n",
      "16 of 325\n",
      "17 of 325\n",
      "18 of 325\n",
      "19 of 325\n",
      "20 of 325\n",
      "21 of 325\n",
      "22 of 325\n",
      "23 of 325\n",
      "24 of 325\n",
      "25 of 325\n",
      "26 of 325\n",
      "27 of 325\n",
      "28 of 325\n",
      "29 of 325\n",
      "30 of 325\n",
      "31 of 325\n",
      "32 of 325\n",
      "33 of 325\n",
      "34 of 325\n",
      "35 of 325\n",
      "36 of 325\n",
      "37 of 325\n",
      "38 of 325\n",
      "39 of 325\n",
      "40 of 325\n",
      "41 of 325\n",
      "42 of 325\n",
      "43 of 325\n",
      "44 of 325\n",
      "45 of 325\n",
      "46 of 325\n",
      "47 of 325\n",
      "48 of 325\n",
      "49 of 325\n",
      "50 of 325\n",
      "52 of 325\n",
      "53 of 325\n",
      "54 of 325\n",
      "55 of 325\n",
      "56 of 325\n",
      "57 of 325\n",
      "58 of 325\n",
      "59 of 325\n",
      "60 of 325\n",
      "61 of 325\n",
      "62 of 325\n",
      "63 of 325\n",
      "64 of 325\n",
      "65 of 325\n",
      "66 of 325\n",
      "67 of 325\n",
      "68 of 325\n",
      "69 of 325\n",
      "70 of 325\n",
      "71 of 325\n",
      "72 of 325\n",
      "73 of 325\n",
      "74 of 325\n",
      "75 of 325\n",
      "76 of 325\n",
      "77 of 325\n",
      "78 of 325\n",
      "79 of 325\n",
      "80 of 325\n",
      "81 of 325\n",
      "82 of 325\n",
      "83 of 325\n",
      "84 of 325\n",
      "85 of 325\n",
      "86 of 325\n",
      "87 of 325\n",
      "88 of 325\n",
      "89 of 325\n",
      "90 of 325\n",
      "91 of 325\n",
      "92 of 325\n",
      "93 of 325\n",
      "94 of 325\n",
      "95 of 325\n",
      "96 of 325\n",
      "97 of 325\n",
      "98 of 325\n",
      "99 of 325\n",
      "100 of 325\n",
      "101 of 325\n",
      "102 of 325\n",
      "103 of 325\n",
      "104 of 325\n",
      "105 of 325\n",
      "106 of 325\n",
      "107 of 325\n",
      "108 of 325\n",
      "109 of 325\n",
      "110 of 325\n",
      "111 of 325\n",
      "112 of 325\n",
      "113 of 325\n",
      "114 of 325\n",
      "115 of 325\n",
      "116 of 325\n",
      "117 of 325\n",
      "118 of 325\n",
      "119 of 325\n",
      "120 of 325\n",
      "121 of 325\n",
      "122 of 325\n",
      "123 of 325\n",
      "124 of 325\n",
      "125 of 325\n",
      "126 of 325\n",
      "127 of 325\n",
      "128 of 325\n",
      "129 of 325\n",
      "130 of 325\n",
      "131 of 325\n",
      "132 of 325\n",
      "133 of 325\n",
      "134 of 325\n",
      "135 of 325\n",
      "136 of 325\n",
      "137 of 325\n",
      "138 of 325\n",
      "139 of 325\n",
      "140 of 325\n",
      "141 of 325\n",
      "142 of 325\n",
      "143 of 325\n",
      "144 of 325\n",
      "145 of 325\n",
      "146 of 325\n",
      "147 of 325\n",
      "148 of 325\n",
      "149 of 325\n",
      "150 of 325\n",
      "151 of 325\n",
      "152 of 325\n",
      "153 of 325\n",
      "154 of 325\n",
      "155 of 325\n",
      "156 of 325\n",
      "157 of 325\n",
      "158 of 325\n",
      "159 of 325\n",
      "160 of 325\n",
      "161 of 325\n",
      "162 of 325\n",
      "163 of 325\n",
      "164 of 325\n",
      "165 of 325\n",
      "166 of 325\n",
      "167 of 325\n",
      "168 of 325\n",
      "169 of 325\n",
      "170 of 325\n",
      "171 of 325\n",
      "172 of 325\n",
      "173 of 325\n",
      "174 of 325\n",
      "175 of 325\n",
      "176 of 325\n",
      "177 of 325\n",
      "178 of 325\n",
      "179 of 325\n",
      "180 of 325\n",
      "181 of 325\n",
      "182 of 325\n",
      "183 of 325\n",
      "184 of 325\n",
      "185 of 325\n",
      "186 of 325\n",
      "187 of 325\n",
      "188 of 325\n",
      "189 of 325\n",
      "190 of 325\n",
      "191 of 325\n",
      "192 of 325\n",
      "193 of 325\n",
      "194 of 325\n",
      "195 of 325\n",
      "196 of 325\n",
      "197 of 325\n",
      "198 of 325\n",
      "199 of 325\n",
      "200 of 325\n",
      "201 of 325\n",
      "202 of 325\n",
      "203 of 325\n",
      "204 of 325\n",
      "205 of 325\n",
      "206 of 325\n",
      "207 of 325\n",
      "208 of 325\n",
      "209 of 325\n",
      "210 of 325\n",
      "211 of 325\n",
      "212 of 325\n",
      "213 of 325\n",
      "214 of 325\n",
      "215 of 325\n",
      "216 of 325\n",
      "217 of 325\n",
      "218 of 325\n",
      "219 of 325\n",
      "220 of 325\n",
      "221 of 325\n",
      "222 of 325\n",
      "223 of 325\n",
      "224 of 325\n",
      "225 of 325\n",
      "226 of 325\n",
      "227 of 325\n",
      "228 of 325\n",
      "229 of 325\n",
      "230 of 325\n",
      "231 of 325\n",
      "232 of 325\n",
      "233 of 325\n",
      "234 of 325\n",
      "235 of 325\n",
      "236 of 325\n",
      "237 of 325\n",
      "238 of 325\n",
      "239 of 325\n",
      "240 of 325\n",
      "241 of 325\n",
      "242 of 325\n",
      "243 of 325\n",
      "244 of 325\n",
      "245 of 325\n",
      "246 of 325\n",
      "247 of 325\n",
      "248 of 325\n",
      "249 of 325\n",
      "250 of 325\n",
      "251 of 325\n",
      "252 of 325\n",
      "253 of 325\n",
      "254 of 325\n",
      "255 of 325\n",
      "256 of 325\n",
      "257 of 325\n",
      "258 of 325\n",
      "259 of 325\n",
      "260 of 325\n",
      "261 of 325\n",
      "262 of 325\n",
      "263 of 325\n",
      "264 of 325\n",
      "265 of 325\n",
      "266 of 325\n",
      "267 of 325\n",
      "268 of 325\n",
      "269 of 325\n",
      "270 of 325\n",
      "271 of 325\n",
      "272 of 325\n",
      "273 of 325\n",
      "274 of 325\n",
      "275 of 325\n",
      "276 of 325\n",
      "277 of 325\n",
      "278 of 325\n",
      "279 of 325\n",
      "280 of 325\n",
      "281 of 325\n",
      "282 of 325\n",
      "283 of 325\n",
      "284 of 325\n",
      "285 of 325\n",
      "286 of 325\n",
      "287 of 325\n",
      "288 of 325\n",
      "289 of 325\n",
      "290 of 325\n",
      "291 of 325\n",
      "292 of 325\n",
      "293 of 325\n",
      "294 of 325\n",
      "295 of 325\n",
      "296 of 325\n",
      "297 of 325\n",
      "298 of 325\n",
      "299 of 325\n",
      "300 of 325\n",
      "301 of 325\n",
      "302 of 325\n",
      "303 of 325\n",
      "304 of 325\n",
      "305 of 325\n",
      "306 of 325\n",
      "307 of 325\n",
      "308 of 325\n",
      "309 of 325\n",
      "310 of 325\n",
      "311 of 325\n",
      "312 of 325\n",
      "313 of 325\n",
      "314 of 325\n",
      "315 of 325\n",
      "316 of 325\n",
      "317 of 325\n",
      "318 of 325\n",
      "319 of 325\n",
      "320 of 325\n",
      "321 of 325\n",
      "322 of 325\n",
      "323 of 325\n",
      "324 of 325\n",
      "325 of 325\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Analysis palms\n",
    "\"\"\"\n",
    "yy = 128 #*4\n",
    "xx = 64 #* 4\n",
    "###GLCMg\n",
    "distances = [1, 2, 4] \n",
    "angles = [0, np.pi/4, np.pi/3]\n",
    "symmetric=False\n",
    "normed=True\n",
    "properties = ['contrast', 'dissimilarity', 'homogeneity', 'energy',\n",
    "                          'correlation', 'ASM']\n",
    "###HOGh\n",
    "orientation=9\n",
    "cellsperblock = (2, 2)\n",
    "pixelspercell = (16, 16)\n",
    "\n",
    "datahog = []\n",
    "labelshog = []\n",
    "dataglcm = []\n",
    "labelsglcm = []\n",
    "globalfeats = []\n",
    "globallabels = []\n",
    "\n",
    "###FLG MUST BE PATH[0]\n",
    "paths =\n",
    " [train_dir_flg_palm, train_dir_wt_palm]\n",
    "imageloader(paths, filter_on=False, norm=False)\n",
    "\n",
    "num_trees = 100\n",
    "seed      = 9\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training classifier...\n",
      "done\n",
      "[STATUS] splitted train and test data...\n",
      "Train data  : (478, 54)\n",
      "Test data   : (54, 54)\n",
      "Train labels: (478,)\n",
      "Test labels : (54,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "GLCM Test 1/2 Palms\n",
    "\"\"\"\n",
    "print(\"[INFO] training classifier...\")\n",
    "models = []\n",
    "\n",
    "models.append(('3NN', KNeighborsClassifier(n_neighbors=3)))\n",
    "models.append(('5NN', KNeighborsClassifier(n_neighbors=5)))\n",
    "models.append(('SVM-L', LinearSVC(random_state=seed, dual=False)))\n",
    "models.append(('SVM-rbf', svm.SVC(kernel='rbf')))\n",
    "print(\"done\")\n",
    "\n",
    "test_size=0.1\n",
    "kfoldsplits=9\n",
    "seed=9\n",
    "\n",
    "datasetx = dataglcm\n",
    "labelsx = labelsglcm\n",
    "trainDataGlobal, testDataGlobal, trainLabelsGlobal, testLabelsGlobal = train_test_split(np.array(datasetx),\n",
    "                                                                                          np.array(labelsx),\n",
    "                                                                                          test_size=test_size,\n",
    "                                                                                          random_state=seed)\n",
    "                                                                                          #shuffle=True) \n",
    "                                                                                                    \n",
    "print(\"[STATUS] splitted train and test data...\")\n",
    "print(\"Train data  : {}\".format(trainDataGlobal.shape))\n",
    "print(\"Test data   : {}\".format(testDataGlobal.shape))\n",
    "print(\"Train labels: {}\".format(trainLabelsGlobal.shape))\n",
    "print(\"Test labels : {}\".format(testLabelsGlobal.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split train and test\n",
      "Train data  : (478, 756)\n",
      "Test data   : (54, 756)\n",
      "Train labels: (478,)\n",
      "Test labels : (54,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "HOG Test 1/2 Palms\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "datasetx = datahog\n",
    "labelsx = labelshog\n",
    "trainDataGlobal, testDataGlobal, trainLabelsGlobal, testLabelsGlobal = train_test_split(np.array(datasetx),\n",
    "                                                                                          np.array(labelsx),\n",
    "                                                                                          test_size=test_size,\n",
    "                                                                                            random_state=seed)\n",
    "                                                                                       #,                                                                   )\n",
    "print(\"Split train and test\")\n",
    "print(\"Train data  : {}\".format(trainDataGlobal.shape))\n",
    "print(\"Test data   : {}\".format(testDataGlobal.shape))\n",
    "print(\"Train labels: {}\".format(trainLabelsGlobal.shape))\n",
    "print(\"Test labels : {}\".format(testLabelsGlobal.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training classifier...\n",
      "done\n",
      "[STATUS] splitted train and test data...\n",
      "Train data  : (478, 54)\n",
      "Test data   : (54, 54)\n",
      "Train labels: (478,)\n",
      "Test labels : (54,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "GLCM Test 1/2 Palms\n",
    "\"\"\"\n",
    "print(\"[INFO] training classifier...\")\n",
    "models = []\n",
    "#models.append(('LogReg', LogisticRegression(random_state=seed)))\n",
    "models.append(('3NN', KNeighborsClassifier(n_neighbors=3)))\n",
    "models.append(('5NN', KNeighborsClassifier(n_neighbors=5)))\n",
    "models.append(('SVM-L', LinearSVC(random_state=seed, dual=False)))\n",
    "models.append(('SVM-rbf', svm.SVC(kernel='rbf')))\n",
    "print(\"done\")\n",
    "\n",
    "test_size=0.1\n",
    "kfoldsplits=9\n",
    "seed=9\n",
    "\n",
    "datasetx = dataglcm\n",
    "labelsx = labelsglcm\n",
    "trainDataGlobal, testDataGlobal, trainLabelsGlobal, testLabelsGlobal = train_test_split(np.array(datasetx),\n",
    "                                                                                          np.array(labelsx),\n",
    "                                                                                          test_size=test_size,\n",
    "                                                                                          random_state=seed)\n",
    "                                                                                          #shuffle=True) \n",
    "                                                                                                    \n",
    "print(\"[STATUS] splitted train and test data...\")\n",
    "print(\"Train data  : {}\".format(trainDataGlobal.shape))\n",
    "print(\"Test data   : {}\".format(testDataGlobal.shape))\n",
    "print(\"Train labels: {}\".format(trainLabelsGlobal.shape))\n",
    "print(\"Test labels : {}\".format(testLabelsGlobal.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNEW GLCM\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "NEW GLCM\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training classifier...\n",
      "done\n",
      "[STATUS] splitted train and test data...\n",
      "Train data  : (477, 54)\n",
      "Test data   : (54, 54)\n",
      "Train labels: (477,)\n",
      "Test labels : (54,)\n"
     ]
    }
   ],
   "source": [
    "###GLCM TESTING 1 OF 2 thenar\n",
    "print(\"[INFO] training classifier...\")\n",
    "models = []\n",
    "models.append(('3NN', KNeighborsClassifier(n_neighbors=3)))\n",
    "models.append(('5NN', KNeighborsClassifier(n_neighbors=5)))\n",
    "models.append(('SVM-L', LinearSVC(random_state=seed, dual=False)))\n",
    "models.append(('SVM-rbf', svm.SVC(kernel='rbf')))\n",
    "print(\"done\")\n",
    "\n",
    "test_size=0.10\n",
    "seed=9\n",
    "kfoldsplits=10\n",
    "datasetx = dataglcm\n",
    "labelsx = labelsglcm\n",
    "trainDataGlobal, testDataGlobal, trainLabelsGlobal, testLabelsGlobal = train_test_split(np.array(datasetx),\n",
    "                                                                                          np.array(labelsx),\n",
    "                                                                                          test_size=test_size,\n",
    "                                                                                          random_state=seed)\n",
    "                                                                                          #shuffle=True) \n",
    "                                                                                                    \n",
    "print(\"[STATUS] splitted train and test data...\")\n",
    "print(\"Train data  : {}\".format(trainDataGlobal.shape))\n",
    "print(\"Test data   : {}\".format(testDataGlobal.shape))\n",
    "print(\"Train labels: {}\".format(trainLabelsGlobal.shape))\n",
    "print(\"Test labels : {}\".format(testLabelsGlobal.shape))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split train and test data...\n",
      "Train data  : (477, 16740)\n",
      "Test data   : (54, 16740)\n",
      "Train labels: (477,)\n",
      "Test labels : (54,)\n"
     ]
    }
   ],
   "source": [
    "###HOG TESTING 1 OF 2\n",
    "\n",
    "datasetx = datahog\n",
    "labelsx = labelshog\n",
    "trainDataGlobal, testDataGlobal, trainLabelsGlobal, testLabelsGlobal = train_test_split(np.array(datasetx),\n",
    "                                                                                          np.array(labelsx),\n",
    "                                                                                          test_size=test_size,\n",
    "                                                                                            random_state=seed)\n",
    "                                                                                       #,                                                                   )\n",
    "print(\"split train and test data...\")\n",
    "print(\"Train data  : {}\".format(trainDataGlobal.shape))\n",
    "print(\"Test data   : {}\".format(testDataGlobal.shape))\n",
    "print(\"Train labels: {}\".format(trainLabelsGlobal.shape))\n",
    "print(\"Test labels : {}\".format(testLabelsGlobal.shape))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3NN: mean is 13.4% with SD 6.0\n",
      "5NN: mean is 8.3% with SD 7.5\n",
      "RF: mean is 20.6% with SD 10.4\n",
      "SVM-L: mean is 42.7% with SD 7.7\n",
      "SVM-rbf: mean is 7.1% with SD 6.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n For each metric you can calculate mean and std value by using:\\n np.mean(results[value]) \\n and \\n np.std(results[value])\\n , where value - one of your specified metric name.\\n'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###HOG TESTING 2 OF 2\n",
    "###GLCM 2 V2\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import make_scorer\n",
    "specificity = make_scorer(recall_score, pos_label=0) #The label 0 is usually the negative class in a binary problem.\n",
    "sensitivity = make_scorer(recall_score, pos_label=1)\n",
    "\n",
    "\n",
    "results = []\n",
    "names   = []\n",
    "#scoring = 'accuracy'\n",
    "#scoring = sensitivity\n",
    "scoring = specificity\n",
    "\n",
    "\n",
    "GLCMHOGtest2()                    \n",
    "\n",
    "   \n",
    "\n",
    "\"\"\"\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_validate\n",
    "iris = load_iris()\n",
    "scoring = ['precision', 'recall', 'f1']\n",
    "clf = SVC(kernel='linear', C=1, random_state=0)\n",
    "scores = cross_validate(clf, iris.data, iris.target == 1, cv=5,\n",
    "                        scoring=scoring, return_train_score=False)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score)}\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    " For each metric you can calculate mean and std value by using:\n",
    " np.mean(results[value]) \n",
    " and \n",
    " np.std(results[value])\n",
    " , where value - one of your specified metric name.\n",
    "\"\"\"\n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/L/Downloads/palmarhyperlinearity/palmarversionall2/flg\n",
      "1 of 208\n",
      "2 of 208\n",
      "3 of 208\n",
      "4 of 208\n",
      "5 of 208\n",
      "6 of 208\n",
      "7 of 208\n",
      "8 of 208\n",
      "9 of 208\n",
      "10 of 208\n",
      "11 of 208\n",
      "12 of 208\n",
      "13 of 208\n",
      "14 of 208\n",
      "15 of 208\n",
      "16 of 208\n",
      "17 of 208\n",
      "18 of 208\n",
      "19 of 208\n",
      "20 of 208\n",
      "21 of 208\n",
      "22 of 208\n",
      "23 of 208\n",
      "24 of 208\n",
      "25 of 208\n",
      "26 of 208\n",
      "27 of 208\n",
      "28 of 208\n",
      "29 of 208\n",
      "30 of 208\n",
      "31 of 208\n",
      "32 of 208\n",
      "33 of 208\n",
      "35 of 208\n",
      "36 of 208\n",
      "37 of 208\n",
      "38 of 208\n",
      "39 of 208\n",
      "40 of 208\n",
      "41 of 208\n",
      "42 of 208\n",
      "43 of 208\n",
      "44 of 208\n",
      "45 of 208\n",
      "46 of 208\n",
      "47 of 208\n",
      "48 of 208\n",
      "49 of 208\n",
      "50 of 208\n",
      "51 of 208\n",
      "52 of 208\n",
      "53 of 208\n",
      "54 of 208\n",
      "55 of 208\n",
      "56 of 208\n",
      "57 of 208\n",
      "58 of 208\n",
      "59 of 208\n",
      "60 of 208\n",
      "61 of 208\n",
      "62 of 208\n",
      "63 of 208\n",
      "64 of 208\n",
      "65 of 208\n",
      "66 of 208\n",
      "67 of 208\n",
      "68 of 208\n",
      "69 of 208\n",
      "70 of 208\n",
      "71 of 208\n",
      "72 of 208\n",
      "73 of 208\n",
      "74 of 208\n",
      "75 of 208\n",
      "76 of 208\n",
      "77 of 208\n",
      "78 of 208\n",
      "79 of 208\n",
      "80 of 208\n",
      "81 of 208\n",
      "82 of 208\n",
      "83 of 208\n",
      "84 of 208\n",
      "85 of 208\n",
      "86 of 208\n",
      "87 of 208\n",
      "88 of 208\n",
      "89 of 208\n",
      "90 of 208\n",
      "91 of 208\n",
      "92 of 208\n",
      "93 of 208\n",
      "94 of 208\n",
      "95 of 208\n",
      "96 of 208\n",
      "97 of 208\n",
      "98 of 208\n",
      "99 of 208\n",
      "100 of 208\n",
      "101 of 208\n",
      "102 of 208\n",
      "103 of 208\n",
      "104 of 208\n",
      "105 of 208\n",
      "106 of 208\n",
      "107 of 208\n",
      "108 of 208\n",
      "109 of 208\n",
      "110 of 208\n",
      "111 of 208\n",
      "112 of 208\n",
      "113 of 208\n",
      "114 of 208\n",
      "115 of 208\n",
      "116 of 208\n",
      "117 of 208\n",
      "118 of 208\n",
      "119 of 208\n",
      "120 of 208\n",
      "121 of 208\n",
      "122 of 208\n",
      "123 of 208\n",
      "124 of 208\n",
      "125 of 208\n",
      "126 of 208\n",
      "127 of 208\n",
      "128 of 208\n",
      "129 of 208\n",
      "130 of 208\n",
      "131 of 208\n",
      "132 of 208\n",
      "133 of 208\n",
      "134 of 208\n",
      "135 of 208\n",
      "136 of 208\n",
      "137 of 208\n",
      "138 of 208\n",
      "139 of 208\n",
      "140 of 208\n",
      "141 of 208\n",
      "142 of 208\n",
      "143 of 208\n",
      "144 of 208\n",
      "145 of 208\n",
      "146 of 208\n",
      "147 of 208\n",
      "148 of 208\n",
      "149 of 208\n",
      "150 of 208\n",
      "151 of 208\n",
      "152 of 208\n",
      "153 of 208\n",
      "154 of 208\n",
      "155 of 208\n",
      "156 of 208\n",
      "157 of 208\n",
      "158 of 208\n",
      "159 of 208\n",
      "160 of 208\n",
      "161 of 208\n",
      "162 of 208\n",
      "163 of 208\n",
      "164 of 208\n",
      "165 of 208\n",
      "166 of 208\n",
      "167 of 208\n",
      "168 of 208\n",
      "169 of 208\n",
      "170 of 208\n",
      "171 of 208\n",
      "172 of 208\n",
      "173 of 208\n",
      "174 of 208\n",
      "175 of 208\n",
      "176 of 208\n",
      "177 of 208\n",
      "178 of 208\n",
      "179 of 208\n",
      "180 of 208\n",
      "181 of 208\n",
      "182 of 208\n",
      "183 of 208\n",
      "184 of 208\n",
      "185 of 208\n",
      "186 of 208\n",
      "187 of 208\n",
      "188 of 208\n",
      "189 of 208\n",
      "190 of 208\n",
      "191 of 208\n",
      "192 of 208\n",
      "193 of 208\n",
      "194 of 208\n",
      "195 of 208\n",
      "196 of 208\n",
      "197 of 208\n",
      "198 of 208\n",
      "199 of 208\n",
      "200 of 208\n",
      "201 of 208\n",
      "202 of 208\n",
      "203 of 208\n",
      "204 of 208\n",
      "205 of 208\n",
      "206 of 208\n",
      "207 of 208\n",
      "208 of 208\n",
      "/Users/L/Downloads/palmarhyperlinearity/palmarversionall2/wt\n",
      "1 of 325\n",
      "2 of 325\n",
      "3 of 325\n",
      "4 of 325\n",
      "5 of 325\n",
      "6 of 325\n",
      "7 of 325\n",
      "8 of 325\n",
      "9 of 325\n",
      "10 of 325\n",
      "11 of 325\n",
      "12 of 325\n",
      "13 of 325\n",
      "14 of 325\n",
      "15 of 325\n",
      "16 of 325\n",
      "17 of 325\n",
      "18 of 325\n",
      "19 of 325\n",
      "20 of 325\n",
      "21 of 325\n",
      "22 of 325\n",
      "23 of 325\n",
      "24 of 325\n",
      "25 of 325\n",
      "26 of 325\n",
      "27 of 325\n",
      "28 of 325\n",
      "29 of 325\n",
      "30 of 325\n",
      "31 of 325\n",
      "32 of 325\n",
      "33 of 325\n",
      "34 of 325\n",
      "35 of 325\n",
      "36 of 325\n",
      "37 of 325\n",
      "38 of 325\n",
      "39 of 325\n",
      "40 of 325\n",
      "41 of 325\n",
      "42 of 325\n",
      "43 of 325\n",
      "44 of 325\n",
      "45 of 325\n",
      "46 of 325\n",
      "47 of 325\n",
      "48 of 325\n",
      "49 of 325\n",
      "50 of 325\n",
      "52 of 325\n",
      "53 of 325\n",
      "54 of 325\n",
      "55 of 325\n",
      "56 of 325\n",
      "57 of 325\n",
      "58 of 325\n",
      "59 of 325\n",
      "60 of 325\n",
      "61 of 325\n",
      "62 of 325\n",
      "63 of 325\n",
      "64 of 325\n",
      "65 of 325\n",
      "66 of 325\n",
      "67 of 325\n",
      "68 of 325\n",
      "69 of 325\n",
      "70 of 325\n",
      "71 of 325\n",
      "72 of 325\n",
      "73 of 325\n",
      "74 of 325\n",
      "75 of 325\n",
      "76 of 325\n",
      "77 of 325\n",
      "78 of 325\n",
      "79 of 325\n",
      "80 of 325\n",
      "81 of 325\n",
      "82 of 325\n",
      "83 of 325\n",
      "84 of 325\n",
      "85 of 325\n",
      "86 of 325\n",
      "87 of 325\n",
      "88 of 325\n",
      "89 of 325\n",
      "90 of 325\n",
      "91 of 325\n",
      "92 of 325\n",
      "93 of 325\n",
      "94 of 325\n",
      "95 of 325\n",
      "96 of 325\n",
      "97 of 325\n",
      "98 of 325\n",
      "99 of 325\n",
      "100 of 325\n",
      "101 of 325\n",
      "102 of 325\n",
      "103 of 325\n",
      "104 of 325\n",
      "105 of 325\n",
      "106 of 325\n",
      "107 of 325\n",
      "108 of 325\n",
      "109 of 325\n",
      "110 of 325\n",
      "111 of 325\n",
      "112 of 325\n",
      "113 of 325\n",
      "114 of 325\n",
      "115 of 325\n",
      "116 of 325\n",
      "117 of 325\n",
      "118 of 325\n",
      "119 of 325\n",
      "120 of 325\n",
      "121 of 325\n",
      "122 of 325\n",
      "123 of 325\n",
      "124 of 325\n",
      "125 of 325\n",
      "126 of 325\n",
      "127 of 325\n",
      "128 of 325\n",
      "129 of 325\n",
      "130 of 325\n",
      "131 of 325\n",
      "132 of 325\n",
      "133 of 325\n",
      "134 of 325\n",
      "135 of 325\n",
      "136 of 325\n",
      "137 of 325\n",
      "138 of 325\n",
      "139 of 325\n",
      "140 of 325\n",
      "141 of 325\n",
      "142 of 325\n",
      "143 of 325\n",
      "144 of 325\n",
      "145 of 325\n",
      "146 of 325\n",
      "147 of 325\n",
      "148 of 325\n",
      "149 of 325\n",
      "150 of 325\n",
      "151 of 325\n",
      "152 of 325\n",
      "153 of 325\n",
      "154 of 325\n",
      "155 of 325\n",
      "156 of 325\n",
      "157 of 325\n",
      "158 of 325\n",
      "159 of 325\n",
      "160 of 325\n",
      "161 of 325\n",
      "162 of 325\n",
      "163 of 325\n",
      "164 of 325\n",
      "165 of 325\n",
      "166 of 325\n",
      "167 of 325\n",
      "168 of 325\n",
      "169 of 325\n",
      "170 of 325\n",
      "171 of 325\n",
      "172 of 325\n",
      "173 of 325\n",
      "174 of 325\n",
      "175 of 325\n",
      "176 of 325\n",
      "177 of 325\n",
      "178 of 325\n",
      "179 of 325\n",
      "180 of 325\n",
      "181 of 325\n",
      "182 of 325\n",
      "183 of 325\n",
      "184 of 325\n",
      "185 of 325\n",
      "186 of 325\n",
      "187 of 325\n",
      "188 of 325\n",
      "189 of 325\n",
      "190 of 325\n",
      "191 of 325\n",
      "192 of 325\n",
      "193 of 325\n",
      "194 of 325\n",
      "195 of 325\n",
      "196 of 325\n",
      "197 of 325\n",
      "198 of 325\n",
      "199 of 325\n",
      "200 of 325\n",
      "201 of 325\n",
      "202 of 325\n",
      "203 of 325\n",
      "204 of 325\n",
      "205 of 325\n",
      "206 of 325\n",
      "207 of 325\n",
      "208 of 325\n",
      "209 of 325\n",
      "210 of 325\n",
      "211 of 325\n",
      "212 of 325\n",
      "213 of 325\n",
      "214 of 325\n",
      "215 of 325\n",
      "216 of 325\n",
      "217 of 325\n",
      "218 of 325\n",
      "219 of 325\n",
      "220 of 325\n",
      "221 of 325\n",
      "222 of 325\n",
      "223 of 325\n",
      "224 of 325\n",
      "225 of 325\n",
      "226 of 325\n",
      "227 of 325\n",
      "228 of 325\n",
      "229 of 325\n",
      "230 of 325\n",
      "231 of 325\n",
      "232 of 325\n",
      "233 of 325\n",
      "234 of 325\n",
      "235 of 325\n",
      "236 of 325\n",
      "237 of 325\n",
      "238 of 325\n",
      "239 of 325\n",
      "240 of 325\n",
      "241 of 325\n",
      "242 of 325\n",
      "243 of 325\n",
      "244 of 325\n",
      "245 of 325\n",
      "246 of 325\n",
      "247 of 325\n",
      "248 of 325\n",
      "249 of 325\n",
      "250 of 325\n",
      "251 of 325\n",
      "252 of 325\n",
      "253 of 325\n",
      "254 of 325\n",
      "255 of 325\n",
      "256 of 325\n",
      "257 of 325\n",
      "258 of 325\n",
      "259 of 325\n",
      "260 of 325\n",
      "261 of 325\n",
      "262 of 325\n",
      "263 of 325\n",
      "264 of 325\n",
      "265 of 325\n",
      "266 of 325\n",
      "267 of 325\n",
      "268 of 325\n",
      "269 of 325\n",
      "270 of 325\n",
      "271 of 325\n",
      "272 of 325\n",
      "273 of 325\n",
      "274 of 325\n",
      "275 of 325\n",
      "276 of 325\n",
      "277 of 325\n",
      "278 of 325\n",
      "279 of 325\n",
      "280 of 325\n",
      "281 of 325\n",
      "282 of 325\n",
      "283 of 325\n",
      "284 of 325\n",
      "285 of 325\n",
      "286 of 325\n",
      "287 of 325\n",
      "288 of 325\n",
      "289 of 325\n",
      "290 of 325\n",
      "291 of 325\n",
      "292 of 325\n",
      "293 of 325\n",
      "294 of 325\n",
      "295 of 325\n",
      "296 of 325\n",
      "297 of 325\n",
      "298 of 325\n",
      "299 of 325\n",
      "300 of 325\n",
      "301 of 325\n",
      "302 of 325\n",
      "303 of 325\n",
      "304 of 325\n",
      "305 of 325\n",
      "306 of 325\n",
      "307 of 325\n",
      "308 of 325\n",
      "309 of 325\n",
      "310 of 325\n",
      "311 of 325\n",
      "312 of 325\n",
      "313 of 325\n",
      "314 of 325\n",
      "315 of 325\n",
      "316 of 325\n",
      "317 of 325\n",
      "318 of 325\n",
      "319 of 325\n",
      "320 of 325\n",
      "321 of 325\n",
      "322 of 325\n",
      "323 of 325\n",
      "324 of 325\n",
      "325 of 325\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Analysis palms\n",
    "\"\"\"\n",
    "yy = 128 #*4\n",
    "xx = 64 #* 4\n",
    "###GLCMg\n",
    "distances = [1, 2, 4] \n",
    "angles = [0, np.pi/4, np.pi/3]\n",
    "symmetric=False\n",
    "normed=True\n",
    "properties = ['contrast', 'dissimilarity', 'homogeneity', 'energy',\n",
    "                          'correlation', 'ASM']\n",
    "###HOGh\n",
    "orientation=9\n",
    "cellsperblock = (2, 2)\n",
    "pixelspercell = (16, 16)\n",
    "\n",
    "datahog = []\n",
    "labelshog = []\n",
    "dataglcm = []\n",
    "labelsglcm = []\n",
    "globalfeats = []\n",
    "globallabels = []\n",
    "\n",
    "###FLG MUST BE PATH[0]\n",
    "paths = [train_dir_flg_palm, train_dir_wt_palm]\n",
    "imageloader(paths, filter_on=False, norm=False)\n",
    "\n",
    "num_trees = 100\n",
    "seed      = 9\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training classifier...\n",
      "done\n",
      "[STATUS] splitted train and test data...\n",
      "Train data  : (477, 54)\n",
      "Test data   : (54, 54)\n",
      "Train labels: (477,)\n",
      "Test labels : (54,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "GLCM Test 1/2 Palms\n",
    "\"\"\"\n",
    "print(\"[INFO] training classifier...\")\n",
    "models = []\n",
    "models.append(('3NN', KNeighborsClassifier(n_neighbors=3)))\n",
    "models.append(('5NN', KNeighborsClassifier(n_neighbors=5)))\n",
    "models.append(('RF', RandomForestClassifier(n_estimators=num_trees, random_state=seed)))\n",
    "models.append(('SVM-L', LinearSVC(random_state=seed, dual=False)))\n",
    "models.append(('SVM-rbf', svm.SVC(kernel='rbf')))\n",
    "print(\"done\")\n",
    "\n",
    "test_size=0.1\n",
    "kfoldsplits=9\n",
    "seed=9\n",
    "\n",
    "datasetx = dataglcm\n",
    "labelsx = labelsglcm\n",
    "trainDataGlobal, testDataGlobal, trainLabelsGlobal, testLabelsGlobal = train_test_split(np.array(datasetx),\n",
    "                                                                                          np.array(labelsx),\n",
    "                                                                                          test_size=test_size,\n",
    "                                                                                          random_state=seed)\n",
    "                                                                                          #shuffle=True) \n",
    "                                                                                                    \n",
    "print(\"[STATUS] splitted train and test data...\")\n",
    "print(\"Train data  : {}\".format(trainDataGlobal.shape))\n",
    "print(\"Test data   : {}\".format(testDataGlobal.shape))\n",
    "print(\"Train labels: {}\".format(trainLabelsGlobal.shape))\n",
    "print(\"Test labels : {}\".format(testLabelsGlobal.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n For each metric you can calculate mean and std value by using:\\n np.mean(results[value]) \\n and \\n np.std(results[value])\\n , where value - one of your specified metric name.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                \n",
    "\n",
    "   \n",
    "\n",
    "\"\"\"\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_validate\n",
    "iris = load_iris()\n",
    "scoring = ['precision', 'recall', 'f1']\n",
    "clf = SVC(kernel='linear', C=1, random_state=0)\n",
    "scores = cross_validate(clf, iris.data, iris.target == 1, cv=5,\n",
    "                        scoring=scoring, return_train_score=False)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score)}\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    " For each metric you can calculate mean and std value by using:\n",
    " np.mean(results[value]) \n",
    " and \n",
    " np.std(results[value])\n",
    " , where value - one of your specified metric name.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### \"\"\"\n",
    "HOG Test 1/2 Palms\n",
    "\"\"\"\n",
    "datasetx = datahog\n",
    "labelsx = labelshog\n",
    "trainDataGlobal, testDataGlobal, trainLabelsGlobal, testLabelsGlobal = train_test_split(np.array(datasetx),\n",
    "                                                                                          np.array(labelsx),\n",
    "                                                                                          test_size=test_size,\n",
    "                                                                                            random_state=seed)          \n",
    "print(\"Split train and test\")\n",
    "print(\"Train data  : {}\".format(trainDataGlobal.shape))\n",
    "print(\"Test data   : {}\".format(testDataGlobal.shape))\n",
    "print(\"Train labels: {}\".format(trainLabelsGlobal.shape))\n",
    "print(\"Test labels : {}\".format(testLabelsGlobal.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GLCMHOGtest2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/87/jz1lkxg141g8vvbsd1q4yh540000gn/T/ipykernel_76695/417657544.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mGLCMHOGtest2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GLCMHOGtest2' is not defined"
     ]
    }
   ],
   "source": [
    "###HOG PALMAR 2 V2\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import make_scorer\n",
    "specificity = make_scorer(recall_score, pos_label=0) #The label 0 is usually the negative class in a binary problem.\n",
    "sensitivity = make_scorer(recall_score, pos_label=1)\n",
    "\n",
    "\n",
    "results = []\n",
    "names   = []\n",
    "\n",
    "scoring = 'accuracy'\n",
    "#scoring = sensitivity\n",
    "#scoring = specificity\n",
    "\n",
    "\n",
    "GLCMHOGtest2()                    \n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\"\"\"\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_validate\n",
    "iris = load_iris()\n",
    "scoring = ['precision', 'recall', 'f1']\n",
    "clf = SVC(kernel='linear', C=1, random_state=0)\n",
    "scores = cross_validate(clf, iris.data, iris.target == 1, cv=5,\n",
    "                        scoring=scoring, return_train_score=False)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score)}\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    " For each metric you can calculate mean and std value by using:\n",
    " np.mean(results[value]) \n",
    " and \n",
    " np.std(results[value])\n",
    " , where value - one of your specified metric name.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extendList(val, list=[]):\n",
    "    list.append(val)\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(extendList(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(extendList(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "print(extendList(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    }
   ],
   "source": [
    "print(extendList(3,[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
