{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "\n",
    "from skimage.filters import roberts, scharr, prewitt, sobel, hessian, frangi, sato, threshold_yen\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from skimage.exposure import equalize_hist\n",
    "from skimage.measure import label, regionprops, regionprops_table\n",
    "from skimage.morphology import erosion, dilation\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.filters import gaussian\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "import numpy as np\n",
    "from skimage import io, color, img_as_ubyte\n",
    "from skimage.measure import label, regionprops, regionprops_table\n",
    "from skimage.feature import hog, corner_moravec, greycomatrix, greycoprops, canny\n",
    "from skimage.exposure import equalize_hist\n",
    "from skimage.filters import sato\n",
    "from skimage import data, exposure, feature\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report,accuracy_score, confusion_matrix \n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "from scipy.stats import mannwhitneyu, f_oneway\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "HOG + HARALICK\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HOGex(img, path):\n",
    "    H = feature.hog(img, orientations=orientation, pixels_per_cell=pixelspercell, cells_per_block=cellsperblock,\n",
    "            transform_sqrt=True, block_norm=\"L1\")\n",
    "    return H\n",
    "def GLCMex(img, path):\n",
    "    glcm = greycomatrix(img, \n",
    "            distances=distances, \n",
    "            angles=angles,\n",
    "            symmetric=symmetric,\n",
    "            normed=normed)\n",
    "    properties=['contrast', 'dissimilarity', 'homogeneity', 'energy',\n",
    "                        'correlation', 'ASM']\n",
    "    feats = np.hstack([greycoprops(glcm, prop).ravel() for prop in properties])\n",
    "    return feats\n",
    "\n",
    "\n",
    "\n",
    "def imageloader(paths, filter_on=False, norm=False, test=False, properties=['contrast', 'dissimilarity', 'homogeneity', 'energy',\n",
    "                          'correlation', 'ASM']):\n",
    "    for path in paths:\n",
    "        print(path)\n",
    "        for i, image_path in enumerate(os.listdir(path)):\n",
    "            if not image_path.startswith('.'):\n",
    "                if test == True:\n",
    "                    if i > 5:\n",
    "                        break\n",
    "                print(f\"{i+1} of {len(os.listdir(path))}\")  \n",
    "                input_path = os.path.join(path, image_path)\n",
    "                img = io.imread(input_path, as_gray=True)\n",
    "                img = resize(img, (yy, xx))\n",
    "                if norm == True:\n",
    "                    img= equalize_hist(img)\n",
    "                if filter_on == True:\n",
    "                    img= sato(img)\n",
    "                img = img_as_ubyte(img)\n",
    "                \"\"\"\n",
    "                featureextraction\n",
    "                \"\"\"\n",
    "                H = HOGex(img, path)\n",
    "                feats = GLCMex(img, path)\n",
    "                \"\"\"\n",
    "                store\n",
    "                \"\"\"\n",
    "                datahog.append(H)\n",
    "                dataglcm.append(feats)\n",
    "                globalfeat = np.hstack([H, feats])\n",
    "                globalfeats.append(globalfeat)\n",
    "                if path == paths[0]:\n",
    "                    flg=1\n",
    "                    globallabels.append(flg)\n",
    "                    labelsglcm.append(flg)\n",
    "                    labelshog.append(flg)\n",
    "                if path == paths[1]:\n",
    "                    flg=0\n",
    "                    globallabels.append(flg)\n",
    "                    labelsglcm.append(flg)\n",
    "                    labelshog.append(flg)\n",
    "\n",
    "def GLCMHOGtest():\n",
    "    for name, model in models:\n",
    "        kfold = KFold(n_splits=kfoldsplits) #random_state=seed)\n",
    "        cv_results = cross_val_score(model, trainDataGlobal, trainLabelsGlobal, cv=kfold, scoring=scoring)\n",
    "        results.append(cv_results)\n",
    "        print(f\"results: {cv_results}\")\n",
    "        names.append(name)\n",
    "        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "        print(msg)\n",
    "        \n",
    "    # boxplot algorithm comparison\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.boxplot(results)\n",
    "#    showmeans=True\n",
    "    ax.set_xticklabels(names)\n",
    "    plt.show()\n",
    "    \n",
    "def GLCMHOGtest2():\n",
    "    for name, model in models:\n",
    "        kfold = KFold(n_splits=kfoldsplits) #random_state=seed)\n",
    "        cv_results = cross_val_score(model, trainDataGlobal, trainLabelsGlobal, cv=kfold, scoring=scoring)\n",
    "        results.append(cv_results)\n",
    "        #print(f\"results: {cv_results}\")\n",
    "        names.append(name)\n",
    "        print(f\"{name}: mean is {cv_results.mean()*100:.1f}% with SD {cv_results.std()*100.0:.1f}\")\n",
    "    # boxplot algorithm comparison\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.boxplot(results)\n",
    "#    showmeans=True\n",
    "    ax.set_xticklabels(names)\n",
    "    plt.show()\n",
    "            #msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    \n",
    "    \n",
    "print(\"done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Users/L/Downloads/palmarhyperlinearity/'\n",
    "base_dir_thenar = '/Users/L/Downloads/palmarhyperlinearity/thenarversionall2/'\n",
    "base_dir_p = '/Users/L/Downloads/palmarhyperlinearity/palmarversionall2/'\n",
    "\n",
    "train_dir_flg_thenar = os.path.join(base_dir_thenar, 'flg')\n",
    "train_dir_wt_thenar = os.path.join(base_dir_thenar, 'wtupdated')\n",
    "\n",
    "train_dir_flg_palm = os.path.join(base_dir_p, 'flg')\n",
    "train_dir_wt_palm = os.path.join(base_dir_p, 'wt')\n",
    "\n",
    "\n",
    "print(f\"Thenar WT photo count: {len(os.listdir(train_dir_wt_thenar))}\")\n",
    "print(f\"Palmar WT photo count: {len(os.listdir(train_dir_wt_palm))}\")\n",
    "\n",
    "print(f\"Thenar FLG photo count: {len(os.listdir(train_dir_flg_thenar))}\")\n",
    "print(f\"Palmar FLG photo count: {len(os.listdir(train_dir_flg_palm ))}\")\n",
    "\n",
    "print(f\"TOTAL photo count: {(len(os.listdir(train_dir_flg_palm))+len(os.listdir(train_dir_wt_palm)))}\")\n",
    "\n",
    "hetero = os.path.join(base_dir_p, 'het')\n",
    "homo = os.path.join(base_dir_p, 'homo')\n",
    "print(f\"hrtro photo count: {len(os.listdir(hetero))}\") ##I THINK THIS INCLUDES .FILE\n",
    "print(f\"homor photo count: {len(os.listdir(homo))}\")\n",
    "flg2 = os.path.join(base_dir_p, 'flg2')\n",
    "print(f\"joint photo count: {len(os.listdir(flg2))}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Joint settings\n",
    "yy = 128  *4\n",
    "xx = 64 * 4\n",
    "\n",
    "###GLCM settings\n",
    "distances = [1, 2, 4] \n",
    "angles = [0, np.pi/4, np.pi/2]\n",
    "    #angles = [0, np.pi/4, np.pi/3]\n",
    "symmetric=False\n",
    "normed=True\n",
    "properties = ['contrast', 'dissimilarity', 'homogeneity', 'energy',\n",
    "                          'correlation', 'ASM']\n",
    "###HOG settings\n",
    "orientation=9\n",
    "cellsperblock = (2, 2)\n",
    "pixelspercell = (16, 16)\n",
    "\n",
    "\n",
    "\n",
    "###lists\n",
    "datahog = []\n",
    "labelshog = []\n",
    "dataglcm = []\n",
    "labelsglcm = []\n",
    "globalfeats = []\n",
    "globallabels = []\n",
    "\n",
    "\n",
    "###LISTS\n",
    "datahog = []\n",
    "labelshog = []\n",
    "dataglcm = []\n",
    "labelsglcm = []\n",
    "globalfeats = []\n",
    "globallabels = []\n",
    "\n",
    "###FLG MUST BE PATH[0]\n",
    "paths = [train_dir_flg_thenar, train_dir_wt_thenar]\n",
    "imageloader(paths, filter_on=False, norm=False)\n",
    "\n",
    "seed      = 9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###GLCM TESTING 1 OF 2\n",
    "print(\"[INFO] training classifier...\")\n",
    "models = []\n",
    "models.append(('3NN', KNeighborsClassifier(n_neighbors=3)))\n",
    "models.append(('5NN', KNeighborsClassifier(n_neighbors=5)))\n",
    "models.append(('SVM-L', LinearSVC(random_state=seed, dual=False)))\n",
    "models.append(('SVM-rbf', svm.SVC(kernel='rbf')))\n",
    "print(\"done\")\n",
    "\n",
    "test_size=0.10\n",
    "seed=9\n",
    "kfoldsplits=10\n",
    "datasetx = dataglcm\n",
    "labelsx = labelsglcm\n",
    "trainDataGlobal, testDataGlobal, trainLabelsGlobal, testLabelsGlobal = train_test_split(np.array(datasetx),\n",
    "                                                                                          np.array(labelsx),\n",
    "                                                                                          test_size=test_size,\n",
    "                                                                                          random_state=seed                                                                           #shuffle=True) \n",
    "                                                                                                    \n",
    "print(\"[STATUS] splitted train and test data...\")\n",
    "print(\"Train data  : {}\".format(trainDataGlobal.shape))\n",
    "print(\"Test data   : {}\".format(testDataGlobal.shape))\n",
    "print(\"Train labels: {}\".format(trainLabelsGlobal.shape))\n",
    "print(\"Test labels : {}\".format(testLabelsGlobal.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####GLCM 2 V2 thEnar\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import make_scorer\n",
    "specificity = make_scorer(recall_score, pos_label=0) #The label 0 is usually the negative class in a binary problem.\n",
    "sensitivity = make_scorer(recall_score, pos_label=1)\n",
    "\n",
    "\n",
    "results = []\n",
    "names   = []\n",
    "\n",
    "#scoring = 'accuracy'\n",
    "#scoring = sensitivity\n",
    "scoring = specificity\n",
    "\n",
    "\n",
    "GLCMHOGtest2()                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Analysis palms\n",
    "\"\"\"\n",
    "yy = 128 #*4\n",
    "xx = 64 #* 4\n",
    "###GLCMg\n",
    "distances = [1, 2, 4] \n",
    "angles = [0, np.pi/4, np.pi/3]\n",
    "symmetric=False\n",
    "normed=True\n",
    "properties = ['contrast', 'dissimilarity', 'homogeneity', 'energy',\n",
    "                          'correlation', 'ASM']\n",
    "###HOGh\n",
    "orientation=9\n",
    "cellsperblock = (2, 2)\n",
    "pixelspercell = (16, 16)\n",
    "\n",
    "datahog = []\n",
    "labelshog = []\n",
    "dataglcm = []\n",
    "labelsglcm = []\n",
    "globalfeats = []\n",
    "globallabels = []\n",
    "\n",
    "###FLG MUST BE PATH[0]\n",
    "paths =\n",
    " [train_dir_flg_palm, train_dir_wt_palm]\n",
    "imageloader(paths, filter_on=False, norm=False)\n",
    "\n",
    "num_trees = 100\n",
    "seed      = 9\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GLCM Test 1/2 Palms\n",
    "\"\"\"\n",
    "print(\"[INFO] training classifier...\")\n",
    "models = []\n",
    "\n",
    "models.append(('3NN', KNeighborsClassifier(n_neighbors=3)))\n",
    "models.append(('5NN', KNeighborsClassifier(n_neighbors=5)))\n",
    "models.append(('SVM-L', LinearSVC(random_state=seed, dual=False)))\n",
    "models.append(('SVM-rbf', svm.SVC(kernel='rbf')))\n",
    "print(\"done\")\n",
    "\n",
    "test_size=0.1\n",
    "kfoldsplits=9\n",
    "seed=9\n",
    "\n",
    "datasetx = dataglcm\n",
    "labelsx = labelsglcm\n",
    "trainDataGlobal, testDataGlobal, trainLabelsGlobal, testLabelsGlobal = train_test_split(np.array(datasetx),\n",
    "                                                                                          np.array(labelsx),\n",
    "                                                                                          test_size=test_size,\n",
    "                                                                                          random_state=seed)\n",
    "                                                                                          #shuffle=True) \n",
    "                                                                                                    \n",
    "print(\"[STATUS] splitted train and test data...\")\n",
    "print(\"Train data  : {}\".format(trainDataGlobal.shape))\n",
    "print(\"Test data   : {}\".format(testDataGlobal.shape))\n",
    "print(\"Train labels: {}\".format(trainLabelsGlobal.shape))\n",
    "print(\"Test labels : {}\".format(testLabelsGlobal.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "HOG Test 1/2 Palms\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "datasetx = datahog\n",
    "labelsx = labelshog\n",
    "trainDataGlobal, testDataGlobal, trainLabelsGlobal, testLabelsGlobal = train_test_split(np.array(datasetx),\n",
    "                                                                                          np.array(labelsx),\n",
    "                                                                                          test_size=test_size,\n",
    "                                                                                            random_state=seed)\n",
    "                                                                                       #,                                                                   )\n",
    "print(\"Split train and test\")\n",
    "print(\"Train data  : {}\".format(trainDataGlobal.shape))\n",
    "print(\"Test data   : {}\".format(testDataGlobal.shape))\n",
    "print(\"Train labels: {}\".format(trainLabelsGlobal.shape))\n",
    "print(\"Test labels : {}\".format(testLabelsGlobal.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GLCM Test 1/2 Palms\n",
    "\"\"\"\n",
    "print(\"[INFO] training classifier...\")\n",
    "models = []\n",
    "#models.append(('LogReg', LogisticRegression(random_state=seed)))\n",
    "models.append(('3NN', KNeighborsClassifier(n_neighbors=3)))\n",
    "models.append(('5NN', KNeighborsClassifier(n_neighbors=5)))\n",
    "models.append(('SVM-L', LinearSVC(random_state=seed, dual=False)))\n",
    "models.append(('SVM-rbf', svm.SVC(kernel='rbf')))\n",
    "print(\"done\")\n",
    "\n",
    "test_size=0.1\n",
    "kfoldsplits=9\n",
    "seed=9\n",
    "\n",
    "datasetx = dataglcm\n",
    "labelsx = labelsglcm\n",
    "trainDataGlobal, testDataGlobal, trainLabelsGlobal, testLabelsGlobal = train_test_split(np.array(datasetx),\n",
    "                                                                                          np.array(labelsx),\n",
    "                                                                                          test_size=test_size,\n",
    "                                                                                          random_state=seed)\n",
    "                                                                                          #shuffle=True) \n",
    "                                                                                                    \n",
    "print(\"[STATUS] splitted train and test data...\")\n",
    "print(\"Train data  : {}\".format(trainDataGlobal.shape))\n",
    "print(\"Test data   : {}\".format(testDataGlobal.shape))\n",
    "print(\"Train labels: {}\".format(trainLabelsGlobal.shape))\n",
    "print(\"Test labels : {}\".format(testLabelsGlobal.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NEW GLCM\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###GLCM TESTING 1 OF 2 thenar\n",
    "print(\"[INFO] training classifier...\")\n",
    "models = []\n",
    "models.append(('3NN', KNeighborsClassifier(n_neighbors=3)))\n",
    "models.append(('5NN', KNeighborsClassifier(n_neighbors=5)))\n",
    "models.append(('SVM-L', LinearSVC(random_state=seed, dual=False)))\n",
    "models.append(('SVM-rbf', svm.SVC(kernel='rbf')))\n",
    "print(\"done\")\n",
    "\n",
    "test_size=0.10\n",
    "seed=9\n",
    "kfoldsplits=10\n",
    "datasetx = dataglcm\n",
    "labelsx = labelsglcm\n",
    "trainDataGlobal, testDataGlobal, trainLabelsGlobal, testLabelsGlobal = train_test_split(np.array(datasetx),\n",
    "                                                                                          np.array(labelsx),\n",
    "                                                                                          test_size=test_size,\n",
    "                                                                                          random_state=seed)\n",
    "                                                                                          #shuffle=True) \n",
    "                                                                                                    \n",
    "print(\"[STATUS] splitted train and test data...\")\n",
    "print(\"Train data  : {}\".format(trainDataGlobal.shape))\n",
    "print(\"Test data   : {}\".format(testDataGlobal.shape))\n",
    "print(\"Train labels: {}\".format(trainLabelsGlobal.shape))\n",
    "print(\"Test labels : {}\".format(testLabelsGlobal.shape))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###HOG TESTING 1 OF 2\n",
    "\n",
    "datasetx = datahog\n",
    "labelsx = labelshog\n",
    "trainDataGlobal, testDataGlobal, trainLabelsGlobal, testLabelsGlobal = train_test_split(np.array(datasetx),\n",
    "                                                                                          np.array(labelsx),\n",
    "                                                                                          test_size=test_size,\n",
    "                                                                                            random_state=seed)\n",
    "                                                                                       #,                                                                   )\n",
    "print(\"split train and test data...\")\n",
    "print(\"Train data  : {}\".format(trainDataGlobal.shape))\n",
    "print(\"Test data   : {}\".format(testDataGlobal.shape))\n",
    "print(\"Train labels: {}\".format(trainLabelsGlobal.shape))\n",
    "print(\"Test labels : {}\".format(testLabelsGlobal.shape))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###HOG TESTING 2 OF 2\n",
    "###GLCM 2 V2\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import make_scorer\n",
    "specificity = make_scorer(recall_score, pos_label=0) #The label 0 is usually the negative class in a binary problem.\n",
    "sensitivity = make_scorer(recall_score, pos_label=1)\n",
    "\n",
    "\n",
    "results = []\n",
    "names   = []\n",
    "#scoring = 'accuracy'\n",
    "#scoring = sensitivity\n",
    "scoring = specificity\n",
    "\n",
    "\n",
    "GLCMHOGtest2()                    \n",
    "\n",
    "   \n",
    "\n",
    "\"\"\"\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_validate\n",
    "iris = load_iris()\n",
    "scoring = ['precision', 'recall', 'f1']\n",
    "clf = SVC(kernel='linear', C=1, random_state=0)\n",
    "scores = cross_validate(clf, iris.data, iris.target == 1, cv=5,\n",
    "                        scoring=scoring, return_train_score=False)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score)}\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    " For each metric you can calculate mean and std value by using:\n",
    " np.mean(results[value]) \n",
    " and \n",
    " np.std(results[value])\n",
    " , where value - one of your specified metric name.\n",
    "\"\"\"\n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Analysis palms\n",
    "\"\"\"\n",
    "yy = 128 #*4\n",
    "xx = 64 #* 4\n",
    "###GLCMg\n",
    "distances = [1, 2, 4] \n",
    "angles = [0, np.pi/4, np.pi/3]\n",
    "symmetric=False\n",
    "normed=True\n",
    "properties = ['contrast', 'dissimilarity', 'homogeneity', 'energy',\n",
    "                          'correlation', 'ASM']\n",
    "###HOGh\n",
    "orientation=9\n",
    "cellsperblock = (2, 2)\n",
    "pixelspercell = (16, 16)\n",
    "\n",
    "datahog = []\n",
    "labelshog = []\n",
    "dataglcm = []\n",
    "labelsglcm = []\n",
    "globalfeats = []\n",
    "globallabels = []\n",
    "\n",
    "###FLG MUST BE PATH[0]\n",
    "paths = [train_dir_flg_palm, train_dir_wt_palm]\n",
    "imageloader(paths, filter_on=False, norm=False)\n",
    "\n",
    "num_trees = 100\n",
    "seed      = 9\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GLCM Test 1/2 Palms\n",
    "\"\"\"\n",
    "print(\"[INFO] training classifier...\")\n",
    "models = []\n",
    "models.append(('3NN', KNeighborsClassifier(n_neighbors=3)))\n",
    "models.append(('5NN', KNeighborsClassifier(n_neighbors=5)))\n",
    "models.append(('RF', RandomForestClassifier(n_estimators=num_trees, random_state=seed)))\n",
    "models.append(('SVM-L', LinearSVC(random_state=seed, dual=False)))\n",
    "models.append(('SVM-rbf', svm.SVC(kernel='rbf')))\n",
    "print(\"done\")\n",
    "\n",
    "test_size=0.1\n",
    "kfoldsplits=9\n",
    "seed=9\n",
    "\n",
    "datasetx = dataglcm\n",
    "labelsx = labelsglcm\n",
    "trainDataGlobal, testDataGlobal, trainLabelsGlobal, testLabelsGlobal = train_test_split(np.array(datasetx),\n",
    "                                                                                          np.array(labelsx),\n",
    "                                                                                          test_size=test_size,\n",
    "                                                                                          random_state=seed)\n",
    "                                                                                          #shuffle=True) \n",
    "                                                                                                    \n",
    "print(\"[STATUS] splitted train and test data...\")\n",
    "print(\"Train data  : {}\".format(trainDataGlobal.shape))\n",
    "print(\"Test data   : {}\".format(testDataGlobal.shape))\n",
    "print(\"Train labels: {}\".format(trainLabelsGlobal.shape))\n",
    "print(\"Test labels : {}\".format(testLabelsGlobal.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                \n",
    "\n",
    "   \n",
    "\n",
    "\"\"\"\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_validate\n",
    "iris = load_iris()\n",
    "scoring = ['precision', 'recall', 'f1']\n",
    "clf = SVC(kernel='linear', C=1, random_state=0)\n",
    "scores = cross_validate(clf, iris.data, iris.target == 1, cv=5,\n",
    "                        scoring=scoring, return_train_score=False)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score)}\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    " For each metric you can calculate mean and std value by using:\n",
    " np.mean(results[value]) \n",
    " and \n",
    " np.std(results[value])\n",
    " , where value - one of your specified metric name.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### \"\"\"\n",
    "HOG Test 1/2 Palms\n",
    "\"\"\"\n",
    "datasetx = datahog\n",
    "labelsx = labelshog\n",
    "trainDataGlobal, testDataGlobal, trainLabelsGlobal, testLabelsGlobal = train_test_split(np.array(datasetx),\n",
    "                                                                                          np.array(labelsx),\n",
    "                                                                                          test_size=test_size,\n",
    "                                                                                            random_state=seed)          \n",
    "print(\"Split train and test\")\n",
    "print(\"Train data  : {}\".format(trainDataGlobal.shape))\n",
    "print(\"Test data   : {}\".format(testDataGlobal.shape))\n",
    "print(\"Train labels: {}\".format(trainLabelsGlobal.shape))\n",
    "print(\"Test labels : {}\".format(testLabelsGlobal.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###HOG PALMAR 2 V2\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import make_scorer\n",
    "specificity = make_scorer(recall_score, pos_label=0) #The label 0 is usually the negative class in a binary problem.\n",
    "sensitivity = make_scorer(recall_score, pos_label=1)\n",
    "\n",
    "\n",
    "results = []\n",
    "names   = []\n",
    "\n",
    "scoring = 'accuracy'\n",
    "#scoring = sensitivity\n",
    "#scoring = specificity\n",
    "\n",
    "\n",
    "GLCMHOGtest2()                    \n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\"\"\"\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_validate\n",
    "iris = load_iris()\n",
    "scoring = ['precision', 'recall', 'f1']\n",
    "clf = SVC(kernel='linear', C=1, random_state=0)\n",
    "scores = cross_validate(clf, iris.data, iris.target == 1, cv=5,\n",
    "                        scoring=scoring, return_train_score=False)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score)}\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    " For each metric you can calculate mean and std value by using:\n",
    " np.mean(results[value]) \n",
    " and \n",
    " np.std(results[value])\n",
    " , where value - one of your specified metric name.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
